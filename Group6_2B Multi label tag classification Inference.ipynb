{"cells": [{"cell_type": "code", "execution_count": 2, "id": "19a96440-eab9-48f3-b8f1-f41b2fbf9e8a", "metadata": {}, "outputs": [], "source": "from pyspark.sql import SparkSession\nfrom pyspark.sql import functions as F\n\nimport matplotlib.pyplot as plt\n%matplotlib inline"}, {"cell_type": "code", "execution_count": 2, "id": "81c3818f-3fab-4eb3-a98b-2b27d56cd447", "metadata": {}, "outputs": [], "source": "#create Spark session\nspark = SparkSession.builder.appName('Stackoverflow_Project').getOrCreate()\n\n#change configuration settings on Spark \nconf = spark.sparkContext._conf.setAll([('spark.executor.memory', '5g'), \n                                        ('spark.app.name', 'Spark Updated Conf'), \n                                        ('spark.executor.cores', '4'), \n                                        ('spark.cores.max', '4'), \n                                        ('spark.driver.memory','8g')])"}, {"cell_type": "code", "execution_count": 1, "id": "cb829fab-85a6-4937-a1c3-ac6885e4e0ef", "metadata": {}, "outputs": [], "source": "spark = (\n    SparkSession.builder\n    .appName(\"Stackoverflow_Project\")\n    .config(\"spark.yarn.maxAppAttempts\", \"4\") \n    .config(\"spark.yarn.am.attemptFailuresValidityInterval\", \"1h\")  \n    .config(\"spark.task.maxFailures\", \"4\")  \n    .config(\"spark.executor.instances\", \"5\")  \n    .config(\"spark.dynamicAllocation.enabled\", \"true\")\n    .config(\"spark.dynamicAllocation.minExecutors\", \"2\")\n    .config(\"spark.dynamicAllocation.maxExecutors\", \"10\")\n    .getOrCreate()\n)\n\n#change configuration settings on Spark \nconf = spark.sparkContext._conf.setAll([('spark.executor.memory', '5g'), \n                                        ('spark.app.name', 'Spark Updated Conf'), \n                                        ('spark.executor.cores', '4'), \n                                        ('spark.cores.max', '4'), \n                                        ('spark.driver.memory','10g')])"}, {"cell_type": "code", "execution_count": 3, "id": "a008f152-182c-4c79-91b0-6d60ebd0e510", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "#Read the cleaned and pre-processed data from the GCS bucket\ndf = spark.read \\\n    .option(\"quote\", \"\\\"\")  \\\n    .option(\"escape\", \"\\\"\") \\\n    .option(\"ignoreLeadingWhiteSpace\",True) \\\n    .parquet(\"gs://msca-bdp-student-gcs/Group6/extracted_StackOverflow.parquet\",inferSchema=True, header=True )"}, {"cell_type": "code", "execution_count": 4, "id": "5313924e-f7b9-418a-98f0-ecefe89675ea", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 1:==================================================>      (25 + 3) / 28]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+----------------+\n|      post_body_text|           post_tags|Count of Answers|\n+--------------------+--------------------+----------------+\n| i only want to p...|javascript|angularjs|               6|\n| i have a table t...|           php|mysql|               7|\n| please check the...|     html|css|colors|               5|\n| not sure if i am...|          python|gis|               7|\n| just learning jq...|javascript|jquery...|               5|\n+--------------------+--------------------+----------------+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "#Data is at answers level, aggregate to get at post level\ndf_2 = df.select('post_body_text','post_tags') \\\n         .groupBy('post_body_text','post_tags').count()\n\ndf_2 = df_2.withColumnRenamed('count', 'Count of Answers')\ndf_2.show(5)"}, {"cell_type": "code", "execution_count": 5, "id": "c56d078e-4b7d-4fec-a161-11b5263545bd", "metadata": {}, "outputs": [], "source": "df_2 = df_2.repartition(40)"}, {"cell_type": "code", "execution_count": 6, "id": "b495e377-5b0b-4d3a-b40e-f8f149b6d538", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "367336"}, "execution_count": 6, "metadata": {}, "output_type": "execute_result"}], "source": "df_2 = df_2.filter(df_2[\"post_body_text\"].isNotNull())\ndf_2 = df_2.dropDuplicates([\"post_body_text\"])\ndf_2.count()"}, {"cell_type": "code", "execution_count": 7, "id": "6b7c7148-9cba-48cb-a9d0-690fe9203726", "metadata": {}, "outputs": [], "source": "from pyspark.sql.functions import split, explode, col, lit, array_contains\n\n#Split tags into an array\ndf_2 = df_2.withColumn(\"tags_array\", split(col(\"post_tags\"), \"\\|\"))\n\n#Explode tags and count frequencies\nexploded_df = df_2.select('post_body_text','post_tags',explode(col(\"tags_array\")).alias(\"tag\"))\ntag_counts = exploded_df.groupBy(\"tag\").count().orderBy(col(\"count\").desc())"}, {"cell_type": "code", "execution_count": 8, "id": "719ee9f2-c4aa-4a90-98b6-35fbcbb9fa51", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 24:===========================================>            (31 + 8) / 40]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+-------------------+\n|      post_body_text|           post_tags|                tag|\n+--------------------+--------------------+-------------------+\n| a beginner quest...|build-process|dev...|      build-process|\n| a beginner quest...|build-process|dev...|development-process|\n| a few years ago ...|                perl|               perl|\n| a friend told me...|c++|performance|c...|                c++|\n| a friend told me...|c++|performance|c...|        performance|\n+--------------------+--------------------+-------------------+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "exploded_df.show(5)"}, {"cell_type": "code", "execution_count": 9, "id": "2c4633da-ee05-4221-a11d-c50aa3a605e5", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "#Select top 50 tags\ntop_50_tags = tag_counts.limit(50).select(\"tag\").rdd.flatMap(lambda x: x).collect()"}, {"cell_type": "code", "execution_count": 10, "id": "2aa42c9a-41e0-4102-862a-3f09ce62cb68", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "502980"}, "execution_count": 10, "metadata": {}, "output_type": "execute_result"}], "source": "#Filter data for top 50 tags\nexploded_df_filtered = exploded_df.filter(col('tag').isin(top_50_tags))\nexploded_df_filtered.count()"}, {"cell_type": "code", "execution_count": 11, "id": "07333853-c2e1-4e4f-9dbf-8cddc6dc269f", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 69:===================>                                      (3 + 6) / 9]\r"}, {"name": "stdout", "output_type": "stream", "text": "root\n |-- post_body_text: string (nullable = true)\n |-- post_tags: string (nullable = true)\n |-- .net: long (nullable = true)\n |-- ajax: long (nullable = true)\n |-- algorithm: long (nullable = true)\n |-- android: long (nullable = true)\n |-- arrays: long (nullable = true)\n |-- asp.net: long (nullable = true)\n |-- asp.net-mvc: long (nullable = true)\n |-- bash: long (nullable = true)\n |-- c: long (nullable = true)\n |-- c#: long (nullable = true)\n |-- c++: long (nullable = true)\n |-- class: long (nullable = true)\n |-- css: long (nullable = true)\n |-- database: long (nullable = true)\n |-- eclipse: long (nullable = true)\n |-- function: long (nullable = true)\n |-- html: long (nullable = true)\n |-- ios: long (nullable = true)\n |-- iphone: long (nullable = true)\n |-- java: long (nullable = true)\n |-- javascript: long (nullable = true)\n |-- jquery: long (nullable = true)\n |-- json: long (nullable = true)\n |-- language-agnostic: long (nullable = true)\n |-- linq: long (nullable = true)\n |-- linux: long (nullable = true)\n |-- list: long (nullable = true)\n |-- multithreading: long (nullable = true)\n |-- mysql: long (nullable = true)\n |-- objective-c: long (nullable = true)\n |-- oop: long (nullable = true)\n |-- performance: long (nullable = true)\n |-- perl: long (nullable = true)\n |-- php: long (nullable = true)\n |-- pointers: long (nullable = true)\n |-- python: long (nullable = true)\n |-- regex: long (nullable = true)\n |-- ruby: long (nullable = true)\n |-- ruby-on-rails: long (nullable = true)\n |-- sql: long (nullable = true)\n |-- sql-server: long (nullable = true)\n |-- string: long (nullable = true)\n |-- tsql: long (nullable = true)\n |-- vb.net: long (nullable = true)\n |-- visual-studio: long (nullable = true)\n |-- windows: long (nullable = true)\n |-- winforms: long (nullable = true)\n |-- wpf: long (nullable = true)\n |-- xcode: long (nullable = true)\n |-- xml: long (nullable = true)\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "#Pivot data\nexploded_df_filtered = exploded_df_filtered.groupBy(\"post_body_text\",\"post_tags\").pivot(\"tag\").count()\nexploded_df_filtered.printSchema()"}, {"cell_type": "code", "execution_count": 12, "id": "df755c34-570d-46b5-b242-ae62ecbae110", "metadata": {}, "outputs": [], "source": "#The dot character triggers an error when used in column names. So rename these columns.\nexploded_df_filtered = exploded_df_filtered.withColumnRenamed('.net', 'dot_net')\nexploded_df_filtered = exploded_df_filtered.withColumnRenamed('asp.net-mvc', 'asp_dot_net-mvc')\nexploded_df_filtered = exploded_df_filtered.withColumnRenamed('asp.net', 'asp_dot_net')\nexploded_df_filtered = exploded_df_filtered.withColumnRenamed('vb.net', 'vb_dot_net')"}, {"cell_type": "code", "execution_count": 13, "id": "891782a2-92de-4d2e-b988-3ee028531ebb", "metadata": {}, "outputs": [{"data": {"text/plain": "['java',\n 'c#',\n 'javascript',\n 'php',\n 'c++',\n 'jquery',\n 'html',\n 'python',\n 'css',\n 'android',\n 'c',\n 'sql',\n 'mysql',\n 'arrays',\n 'string',\n 'sql-server',\n 'iphone',\n 'ios',\n 'regex',\n 'objective-c',\n 'algorithm',\n 'ruby',\n 'performance',\n 'database',\n 'linux',\n 'ruby-on-rails',\n 'windows',\n 'list',\n 'multithreading',\n 'oop',\n 'bash',\n 'eclipse',\n 'ajax',\n 'perl',\n 'json',\n 'pointers',\n 'visual-studio',\n 'xml',\n 'winforms',\n 'linq',\n 'function',\n 'class',\n 'tsql',\n 'wpf',\n 'xcode',\n 'language-agnostic',\n 'asp_dot_net',\n 'asp_dot_net-mvc',\n 'vb_dot_net',\n 'dot_net']"}, "execution_count": 13, "metadata": {}, "output_type": "execute_result"}], "source": "#Also rename in tags list\ntop_50_tags.remove('.net')\ntop_50_tags.remove('asp.net-mvc')\ntop_50_tags.remove('asp.net')\ntop_50_tags.remove('vb.net')\ntop_50_tags = top_50_tags + ['asp_dot_net','asp_dot_net-mvc','vb_dot_net','dot_net']\ntop_50_tags"}, {"cell_type": "code", "execution_count": 14, "id": "59039403-4528-4864-9cc8-35082b067fe0", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/01 19:32:34 WARN org.apache.spark.sql.catalyst.util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n[Stage 86:============================================>           (32 + 8) / 40]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+-------+----+---------+-------+------+-----------+---------------+----+---+---+---+-----+---+--------+-------+--------+----+---+------+----+----------+------+----+-----------------+----+-----+----+--------------+-----+-----------+---+-----------+----+---+--------+------+-----+----+-------------+---+----------+------+----+----------+-------------+-------+--------+---+-----+---+\n|      post_body_text|           post_tags|dot_net|ajax|algorithm|android|arrays|asp_dot_net|asp_dot_net-mvc|bash|  c| c#|c++|class|css|database|eclipse|function|html|ios|iphone|java|javascript|jquery|json|language-agnostic|linq|linux|list|multithreading|mysql|objective-c|oop|performance|perl|php|pointers|python|regex|ruby|ruby-on-rails|sql|sql-server|string|tsql|vb_dot_net|visual-studio|windows|winforms|wpf|xcode|xml|\n+--------------------+--------------------+-------+----+---------+-------+------+-----------+---------------+----+---+---+---+-----+---+--------+-------+--------+----+---+------+----+----------+------+----+-----------------+----+-----+----+--------------+-----+-----------+---+-----------+----+---+--------+------+-----+----+-------------+---+----------+------+----+----------+-------------+-------+--------+---+-----+---+\n| a few years ago ...|                perl|      0|   0|        0|      0|     0|          0|              0|   0|  0|  0|  0|    0|  0|       0|      0|       0|   0|  0|     0|   0|         0|     0|   0|                0|   0|    0|   0|             0|    0|          0|  0|          0|   1|  0|       0|     0|    0|   0|            0|  0|         0|     0|   0|         0|            0|      0|       0|  0|    0|  0|\n| a friend told me...|c++|performance|c...|      0|   0|        0|      0|     0|          0|              0|   0|  0|  0|  1|    0|  0|       0|      0|       0|   0|  0|     0|   0|         0|     0|   0|                0|   0|    0|   0|             0|    0|          0|  0|          1|   0|  0|       0|     0|    0|   0|            0|  0|         0|     0|   0|         0|            0|      0|       0|  0|    0|  0|\n| a net program is...|     c#|.net|clr|jit|      1|   0|        0|      0|     0|          0|              0|   0|  0|  1|  0|    0|  0|       0|      0|       0|   0|  0|     0|   0|         0|     0|   0|                0|   0|    0|   0|             0|    0|          0|  0|          0|   0|  0|       0|     0|    0|   0|            0|  0|         0|     0|   0|         0|            0|      0|       0|  0|    0|  0|\n| a sequence is bi...|           algorithm|      0|   0|        1|      0|     0|          0|              0|   0|  0|  0|  0|    0|  0|       0|      0|       0|   0|  0|     0|   0|         0|     0|   0|                0|   0|    0|   0|             0|    0|          0|  0|          0|   0|  0|       0|     0|    0|   0|            0|  0|         0|     0|   0|         0|            0|      0|       0|  0|    0|  0|\n| a string is an a...|                 php|      0|   0|        0|      0|     0|          0|              0|   0|  0|  0|  0|    0|  0|       0|      0|       0|   0|  0|     0|   0|         0|     0|   0|                0|   0|    0|   0|             0|    0|          0|  0|          0|   0|  1|       0|     0|    0|   0|            0|  0|         0|     0|   0|         0|            0|      0|       0|  0|    0|  0|\n+--------------------+--------------------+-------+----+---------+-------+------+-----------+---------------+----+---+---+---+-----+---+--------+-------+--------+----+---+------+----+----------+------+----+-----------------+----+-----+----+--------------+-----+-----------+---+-----------+----+---+--------+------+-----+----+-------------+---+----------+------+----+----------+-------------+-------+--------+---+-----+---+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "#Since there are lot of null values because of pivoting the df, fill null values with 0s\nexploded_df_filtered = exploded_df_filtered.na.fill(value = 0)\nexploded_df_filtered.show(5)"}, {"cell_type": "markdown", "id": "b1424586-b5b0-464a-b160-6aa6a72fa9c8", "metadata": {}, "source": "### Create pipeline for feature engineering/data transformation"}, {"cell_type": "code", "execution_count": 15, "id": "a24bc76b-f7eb-4795-a9e5-a9c80a4cf93a", "metadata": {}, "outputs": [], "source": "#Spark ML imports\nfrom pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression, LogisticRegressionModel\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\n#Tokenize the data into words\ntokenizer = Tokenizer(inputCol=\"post_body_text\", outputCol=\"Words\")\n\n#Remove stop words\nremove_stopwords = StopWordsRemover(inputCol=\"Words\", outputCol=\"Filtered_Words\")\n\n#HashingTF\nhashing_tf = HashingTF(inputCol=\"Filtered_Words\", outputCol=\"Hashing_TF_Features\")\n\n#IDF\nidf = IDF(inputCol=\"Hashing_TF_Features\", outputCol=\"Hashing_TFIDF_Features\")\n\n#Creating a pipeline to transform the data and prepare it for the model\npipeline = Pipeline(stages=[tokenizer, remove_stopwords, hashing_tf, idf])"}, {"cell_type": "code", "execution_count": 16, "id": "81d763d3-e4bd-4bab-9a75-03cb21a27cb9", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 100:===================================================> (195 + 5) / 200]\r"}, {"name": "stdout", "output_type": "stream", "text": "root\n |-- post_body_text: string (nullable = true)\n |-- post_tags: string (nullable = true)\n |-- dot_net: long (nullable = true)\n |-- ajax: long (nullable = true)\n |-- algorithm: long (nullable = true)\n |-- android: long (nullable = true)\n |-- arrays: long (nullable = true)\n |-- asp_dot_net: long (nullable = true)\n |-- asp_dot_net-mvc: long (nullable = true)\n |-- bash: long (nullable = true)\n |-- c: long (nullable = true)\n |-- c#: long (nullable = true)\n |-- c++: long (nullable = true)\n |-- class: long (nullable = true)\n |-- css: long (nullable = true)\n |-- database: long (nullable = true)\n |-- eclipse: long (nullable = true)\n |-- function: long (nullable = true)\n |-- html: long (nullable = true)\n |-- ios: long (nullable = true)\n |-- iphone: long (nullable = true)\n |-- java: long (nullable = true)\n |-- javascript: long (nullable = true)\n |-- jquery: long (nullable = true)\n |-- json: long (nullable = true)\n |-- language-agnostic: long (nullable = true)\n |-- linq: long (nullable = true)\n |-- linux: long (nullable = true)\n |-- list: long (nullable = true)\n |-- multithreading: long (nullable = true)\n |-- mysql: long (nullable = true)\n |-- objective-c: long (nullable = true)\n |-- oop: long (nullable = true)\n |-- performance: long (nullable = true)\n |-- perl: long (nullable = true)\n |-- php: long (nullable = true)\n |-- pointers: long (nullable = true)\n |-- python: long (nullable = true)\n |-- regex: long (nullable = true)\n |-- ruby: long (nullable = true)\n |-- ruby-on-rails: long (nullable = true)\n |-- sql: long (nullable = true)\n |-- sql-server: long (nullable = true)\n |-- string: long (nullable = true)\n |-- tsql: long (nullable = true)\n |-- vb_dot_net: long (nullable = true)\n |-- visual-studio: long (nullable = true)\n |-- windows: long (nullable = true)\n |-- winforms: long (nullable = true)\n |-- wpf: long (nullable = true)\n |-- xcode: long (nullable = true)\n |-- xml: long (nullable = true)\n |-- Words: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- Filtered_Words: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- Hashing_TF_Features: vector (nullable = true)\n |-- Hashing_TFIDF_Features: vector (nullable = true)\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "#Fit and transform the data using the pipeline\npipeline_final = pipeline.fit(exploded_df_filtered)\nmodel_df = pipeline_final.transform(exploded_df_filtered)\nmodel_df.printSchema()"}, {"cell_type": "code", "execution_count": 17, "id": "f0cbae50-56c6-4589-8aa0-c018d117265c", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "318648"}, "execution_count": 17, "metadata": {}, "output_type": "execute_result"}], "source": "#Remove duplicates\nmodel_df = model_df.dropDuplicates([\"post_body_text\"])\nmodel_df = model_df.filter(model_df[\"post_body_text\"].isNotNull())\nmodel_df = model_df.filter(model_df[\"post_tags\"].isNotNull())\nmodel_df.count()"}, {"cell_type": "code", "execution_count": 18, "id": "3641f7c5-84dd-4145-ae0d-d3dd26769a83", "metadata": {}, "outputs": [], "source": "# Split the data into train (70%), test (20%), and validation (10%) sets\ntrain_df, test_df, val_df = model_df.randomSplit([0.7, 0.2, 0.1], seed=11)"}, {"cell_type": "markdown", "id": "15a92b00-5412-4303-bc85-c2a706c54b5f", "metadata": {}, "source": "### Load the models from GCS for inference"}, {"cell_type": "code", "execution_count": 19, "id": "03e2ad20-137d-417a-a9e2-f0bf24e30f8b", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/01 19:33:22 WARN org.apache.hadoop.util.concurrent.ExecutorHelper: Thread (Thread[GetFileInfo #1,5,main]) interrupted: \njava.lang.InterruptedException\n\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:510)\n\tat com.google.common.util.concurrent.FluentFuture$TrustedFuture.get(FluentFuture.java:88)\n\tat org.apache.hadoop.util.concurrent.ExecutorHelper.logThrowableFromAfterExecute(ExecutorHelper.java:48)\n\tat org.apache.hadoop.util.concurrent.HadoopThreadPoolExecutor.afterExecute(HadoopThreadPoolExecutor.java:90)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1157)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n24/12/01 19:33:52 WARN org.apache.hadoop.util.concurrent.ExecutorHelper: Thread (Thread[GetFileInfo #1,5,main]) interrupted: \njava.lang.InterruptedException\n\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:510)\n\tat com.google.common.util.concurrent.FluentFuture$TrustedFuture.get(FluentFuture.java:88)\n\tat org.apache.hadoop.util.concurrent.ExecutorHelper.logThrowableFromAfterExecute(ExecutorHelper.java:48)\n\tat org.apache.hadoop.util.concurrent.HadoopThreadPoolExecutor.afterExecute(HadoopThreadPoolExecutor.java:90)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1157)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n"}], "source": "loaded_models = []\n\nfor i in range(0,50):\n    tag = top_50_tags[i]\n\n    # Path to save the model in GCS\n    gcs_model_path = f'gs://msca-bdp-student-gcs/Group6/Tag_classification_models/Log_Reg_{tag}'\n\n    # Save the trained logistic regression model\n    loaded_model = LogisticRegressionModel.load(gcs_model_path)\n    \n    loaded_models.append({\n        \"tag\": tag,\n        \"Log_reg_htfidf_model\": loaded_model})"}, {"cell_type": "code", "execution_count": 20, "id": "c2817359-af40-4215-9bb1-3458165001e4", "metadata": {}, "outputs": [{"data": {"text/plain": "{'tag': 'java',\n 'Log_reg_htfidf_model': LogisticRegressionModel: uid=LogisticRegression_1480097e889f, numClasses=2, numFeatures=262144}"}, "execution_count": 20, "metadata": {}, "output_type": "execute_result"}], "source": "loaded_models[0]"}, {"cell_type": "markdown", "id": "11adc53d-f4e4-455e-a371-ff6d15597911", "metadata": {}, "source": "### Inference - Validation Data"}, {"cell_type": "code", "execution_count": 21, "id": "20d1022c-a525-4bcf-9575-bdac4ab96c7c", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/01 19:34:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n                                                                                \r"}, {"data": {"text/plain": "32032"}, "execution_count": 21, "metadata": {}, "output_type": "execute_result"}], "source": "#Remove duplicates\nval_df = val_df.dropDuplicates([\"post_body_text\"])\nval_df = val_df.filter(val_df[\"post_body_text\"].isNotNull())\nval_df = val_df.filter(val_df[\"post_tags\"].isNotNull())\nval_df.count()"}, {"cell_type": "code", "execution_count": 22, "id": "e80352b9-99f7-4d13-9a5b-2141c82d3482", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/01 19:34:39 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+\n|      post_body_text|           post_tags|\n+--------------------+--------------------+\n| all thanks for t...|objective-c|array...|\n| am newbie in lar...|         php|laravel|\n| am using it in w...|jquery|wordpress|...|\n| are there any go...| java|python|parsing|\n| as the question ...|jquery|drop-down-...|\n+--------------------+--------------------+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "results_validation_data = val_df.select(\"post_body_text\",\"post_tags\")\nresults_validation_data.show(5)"}, {"cell_type": "code", "execution_count": 23, "id": "b4877384-a7d0-46ef-9f4a-014e83784b07", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/01 19:34:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n                                                                                \r"}, {"data": {"text/plain": "31986"}, "execution_count": 23, "metadata": {}, "output_type": "execute_result"}], "source": "results_validation_data.count()"}, {"cell_type": "code", "execution_count": 24, "id": "1466bc2d-27f3-43bb-9c92-fdb431a5b573", "metadata": {}, "outputs": [], "source": "predictions_tags = []"}, {"cell_type": "code", "execution_count": 25, "id": "0ac0fcf2-3a1b-498c-ae66-b33ab7adac11", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/01 19:36:37 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:37:09 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:37:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:37:48 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:38:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:38:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:38:39 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:38:55 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:39:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:39:27 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:39:45 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:40:03 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:40:19 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:40:36 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:40:54 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:41:09 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:41:26 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:41:43 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:41:58 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:42:18 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:42:45 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:42:57 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:43:07 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:43:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:43:28 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:43:38 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:43:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:43:57 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:44:07 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:44:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:44:27 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:44:38 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:44:48 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:44:58 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:45:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:45:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:45:27 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:45:36 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:45:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:45:56 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:46:05 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:46:15 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:46:25 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:46:38 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:46:57 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:47:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:47:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:47:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:47:40 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/01 19:47:49 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n                                                                                \r"}], "source": "for i in range(0,50):\n    tag = loaded_models[i]['tag']\n    Log_reg_model = loaded_models[i]['Log_reg_htfidf_model']\n    predictions = Log_reg_model.transform(val_df)\n    predictions_column = predictions.select(\"post_body_text\",col(\"prediction\").alias(tag))\n    predictions_column = predictions_column.withColumnRenamed(\"post_body_text\",f\"post_body_text_{i}\")\n    \n    predictions_tags.append({\n        \"tag\":tag,\n        \"predictions_column\":predictions_column,\n        \"count_rows\":predictions_column.count()\n    })"}, {"cell_type": "code", "execution_count": 26, "id": "398f2ef6-9b03-4ac1-bc69-7be79b482f64", "metadata": {}, "outputs": [{"data": {"text/plain": "[{'tag': 'java',\n  'predictions_column': DataFrame[post_body_text_0: string, java: double],\n  'count_rows': 31986},\n {'tag': 'c#',\n  'predictions_column': DataFrame[post_body_text_1: string, c#: double],\n  'count_rows': 31986},\n {'tag': 'javascript',\n  'predictions_column': DataFrame[post_body_text_2: string, javascript: double],\n  'count_rows': 31986},\n {'tag': 'php',\n  'predictions_column': DataFrame[post_body_text_3: string, php: double],\n  'count_rows': 31986},\n {'tag': 'c++',\n  'predictions_column': DataFrame[post_body_text_4: string, c++: double],\n  'count_rows': 31986},\n {'tag': 'jquery',\n  'predictions_column': DataFrame[post_body_text_5: string, jquery: double],\n  'count_rows': 31986},\n {'tag': 'html',\n  'predictions_column': DataFrame[post_body_text_6: string, html: double],\n  'count_rows': 31986},\n {'tag': 'python',\n  'predictions_column': DataFrame[post_body_text_7: string, python: double],\n  'count_rows': 31986},\n {'tag': 'css',\n  'predictions_column': DataFrame[post_body_text_8: string, css: double],\n  'count_rows': 31986},\n {'tag': 'android',\n  'predictions_column': DataFrame[post_body_text_9: string, android: double],\n  'count_rows': 31986},\n {'tag': 'c',\n  'predictions_column': DataFrame[post_body_text_10: string, c: double],\n  'count_rows': 31986},\n {'tag': 'sql',\n  'predictions_column': DataFrame[post_body_text_11: string, sql: double],\n  'count_rows': 31986},\n {'tag': 'mysql',\n  'predictions_column': DataFrame[post_body_text_12: string, mysql: double],\n  'count_rows': 31986},\n {'tag': 'arrays',\n  'predictions_column': DataFrame[post_body_text_13: string, arrays: double],\n  'count_rows': 31986},\n {'tag': 'string',\n  'predictions_column': DataFrame[post_body_text_14: string, string: double],\n  'count_rows': 31986},\n {'tag': 'sql-server',\n  'predictions_column': DataFrame[post_body_text_15: string, sql-server: double],\n  'count_rows': 31986},\n {'tag': 'iphone',\n  'predictions_column': DataFrame[post_body_text_16: string, iphone: double],\n  'count_rows': 31986},\n {'tag': 'ios',\n  'predictions_column': DataFrame[post_body_text_17: string, ios: double],\n  'count_rows': 31986},\n {'tag': 'regex',\n  'predictions_column': DataFrame[post_body_text_18: string, regex: double],\n  'count_rows': 31986},\n {'tag': 'objective-c',\n  'predictions_column': DataFrame[post_body_text_19: string, objective-c: double],\n  'count_rows': 32000},\n {'tag': 'algorithm',\n  'predictions_column': DataFrame[post_body_text_20: string, algorithm: double],\n  'count_rows': 32000},\n {'tag': 'ruby',\n  'predictions_column': DataFrame[post_body_text_21: string, ruby: double],\n  'count_rows': 32000},\n {'tag': 'performance',\n  'predictions_column': DataFrame[post_body_text_22: string, performance: double],\n  'count_rows': 32000},\n {'tag': 'database',\n  'predictions_column': DataFrame[post_body_text_23: string, database: double],\n  'count_rows': 32000},\n {'tag': 'linux',\n  'predictions_column': DataFrame[post_body_text_24: string, linux: double],\n  'count_rows': 32000},\n {'tag': 'ruby-on-rails',\n  'predictions_column': DataFrame[post_body_text_25: string, ruby-on-rails: double],\n  'count_rows': 32000},\n {'tag': 'windows',\n  'predictions_column': DataFrame[post_body_text_26: string, windows: double],\n  'count_rows': 32001},\n {'tag': 'list',\n  'predictions_column': DataFrame[post_body_text_27: string, list: double],\n  'count_rows': 32000},\n {'tag': 'multithreading',\n  'predictions_column': DataFrame[post_body_text_28: string, multithreading: double],\n  'count_rows': 32000},\n {'tag': 'oop',\n  'predictions_column': DataFrame[post_body_text_29: string, oop: double],\n  'count_rows': 32000},\n {'tag': 'bash',\n  'predictions_column': DataFrame[post_body_text_30: string, bash: double],\n  'count_rows': 32001},\n {'tag': 'eclipse',\n  'predictions_column': DataFrame[post_body_text_31: string, eclipse: double],\n  'count_rows': 32000},\n {'tag': 'ajax',\n  'predictions_column': DataFrame[post_body_text_32: string, ajax: double],\n  'count_rows': 32000},\n {'tag': 'perl',\n  'predictions_column': DataFrame[post_body_text_33: string, perl: double],\n  'count_rows': 32001},\n {'tag': 'json',\n  'predictions_column': DataFrame[post_body_text_34: string, json: double],\n  'count_rows': 32000},\n {'tag': 'pointers',\n  'predictions_column': DataFrame[post_body_text_35: string, pointers: double],\n  'count_rows': 32000},\n {'tag': 'visual-studio',\n  'predictions_column': DataFrame[post_body_text_36: string, visual-studio: double],\n  'count_rows': 32000},\n {'tag': 'xml',\n  'predictions_column': DataFrame[post_body_text_37: string, xml: double],\n  'count_rows': 32000},\n {'tag': 'winforms',\n  'predictions_column': DataFrame[post_body_text_38: string, winforms: double],\n  'count_rows': 32000},\n {'tag': 'linq',\n  'predictions_column': DataFrame[post_body_text_39: string, linq: double],\n  'count_rows': 32001},\n {'tag': 'function',\n  'predictions_column': DataFrame[post_body_text_40: string, function: double],\n  'count_rows': 32001},\n {'tag': 'class',\n  'predictions_column': DataFrame[post_body_text_41: string, class: double],\n  'count_rows': 32001},\n {'tag': 'tsql',\n  'predictions_column': DataFrame[post_body_text_42: string, tsql: double],\n  'count_rows': 32000},\n {'tag': 'wpf',\n  'predictions_column': DataFrame[post_body_text_43: string, wpf: double],\n  'count_rows': 32039},\n {'tag': 'xcode',\n  'predictions_column': DataFrame[post_body_text_44: string, xcode: double],\n  'count_rows': 31990},\n {'tag': 'language-agnostic',\n  'predictions_column': DataFrame[post_body_text_45: string, language-agnostic: double],\n  'count_rows': 31990},\n {'tag': 'asp_dot_net',\n  'predictions_column': DataFrame[post_body_text_46: string, asp_dot_net: double],\n  'count_rows': 31990},\n {'tag': 'asp_dot_net-mvc',\n  'predictions_column': DataFrame[post_body_text_47: string, asp_dot_net-mvc: double],\n  'count_rows': 31990},\n {'tag': 'vb_dot_net',\n  'predictions_column': DataFrame[post_body_text_48: string, vb_dot_net: double],\n  'count_rows': 31989},\n {'tag': 'dot_net',\n  'predictions_column': DataFrame[post_body_text_49: string, dot_net: double],\n  'count_rows': 31990}]"}, "execution_count": 26, "metadata": {}, "output_type": "execute_result"}], "source": "predictions_tags"}, {"cell_type": "code", "execution_count": 27, "id": "d63a5588-5a6c-4a2c-868d-b4c81de5f2bc", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "java : 31986\nc# : 31986\njavascript : 31986\nphp : 31986\nc++ : 31986\njquery : 31986\nhtml : 31986\npython : 31986\ncss : 31986\nandroid : 31986\nc : 31986\nsql : 31986\nmysql : 31986\narrays : 31986\nstring : 31986\nsql-server : 31986\niphone : 31986\nios : 31986\nregex : 31986\nobjective-c : 32000\nalgorithm : 32000\nruby : 32000\nperformance : 32000\ndatabase : 32000\nlinux : 32000\nruby-on-rails : 32000\nwindows : 32001\nlist : 32000\nmultithreading : 32000\noop : 32000\nbash : 32001\neclipse : 32000\najax : 32000\nperl : 32001\njson : 32000\npointers : 32000\nvisual-studio : 32000\nxml : 32000\nwinforms : 32000\nlinq : 32001\nfunction : 32001\nclass : 32001\ntsql : 32000\nwpf : 32039\nxcode : 31990\nlanguage-agnostic : 31990\nasp_dot_net : 31990\nasp_dot_net-mvc : 31990\nvb_dot_net : 31989\ndot_net : 31990\n"}], "source": "for i in range(0,50):\n    print(predictions_tags[i]['tag'],\":\",predictions_tags[i]['count_rows'])"}, {"cell_type": "code", "execution_count": 28, "id": "70035278-c48d-4ad8-ad0d-1b6fa4274f67", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "completed iteration0\ncompleted iteration1\ncompleted iteration2\ncompleted iteration3\ncompleted iteration4\ncompleted iteration5\ncompleted iteration6\ncompleted iteration7\ncompleted iteration8\ncompleted iteration9\n"}], "source": "for i in range(0,10):\n    #Join predictions back to the results DataFrame\n    predictions_column = predictions_tags[i]['predictions_column']\n    results_validation_data = results_validation_data.join(predictions_column, \n                                                   results_validation_data[\"post_body_text\"] == predictions_column[f\"post_body_text_{i}\"], \n                                                   how='inner')  \n    results_validation_data = results_validation_data.drop(f\"post_body_text_{i}\")\n    print(f'completed iteration{i}')"}, {"cell_type": "code", "execution_count": 29, "id": "b4115ff0-121b-453c-a015-5d4a18738ecd", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/01 19:50:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:50:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:50:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:50:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:50:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:50:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:50:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:50:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:50:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:50:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:51:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n[Stage 1079:>                                                       (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+----+---+----------+---+---+------+----+------+---+-------+\n|      post_body_text|           post_tags|java| c#|javascript|php|c++|jquery|html|python|css|android|\n+--------------------+--------------------+----+---+----------+---+---+------+----+------+---+-------+\n| am newbie in lar...|         php|laravel| 0.0|0.0|       0.0|1.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|\n| below is my conn...| c#|entity-framework| 0.0|1.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|\n| i am developing ...|android|google-pl...| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    1.0|\n| i dont quite und...|php|model-view-co...| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|\n| i followed the h...|android|unit-testing| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|\n+--------------------+--------------------+----+---+----------+---+---+------+----+------+---+-------+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "results_validation_data.show(5)"}, {"cell_type": "code", "execution_count": 30, "id": "a115b962-bf47-4913-bcdb-90344cb6876f", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "completed iteration10\ncompleted iteration11\ncompleted iteration12\ncompleted iteration13\ncompleted iteration14\ncompleted iteration15\ncompleted iteration16\ncompleted iteration17\ncompleted iteration18\ncompleted iteration19\n"}], "source": "for i in range(10,20):\n    #Join predictions back to the results DataFrame\n    predictions_column = predictions_tags[i]['predictions_column']\n    results_validation_data = results_validation_data.join(predictions_column, \n                                                   results_validation_data[\"post_body_text\"] == predictions_column[f\"post_body_text_{i}\"], \n                                                   how='inner')  \n    results_validation_data = results_validation_data.drop(f\"post_body_text_{i}\")\n    print(f'completed iteration{i}')"}, {"cell_type": "code", "execution_count": 31, "id": "90badd65-f3d1-4345-b4a4-caeab3f2ff66", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/01 19:53:45 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:53:45 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:53:45 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:53:46 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:53:46 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:53:46 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:53:46 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:53:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:53:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:53:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:53:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:53:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:53:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:53:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:53:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:53:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:53:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:53:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:53:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:53:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:55:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n[Stage 1112:>                                                       (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+----+---+----------+---+---+------+----+------+---+-------+---+---+-----+------+------+----------+------+---+-----+-----------+\n|      post_body_text|           post_tags|java| c#|javascript|php|c++|jquery|html|python|css|android|  c|sql|mysql|arrays|string|sql-server|iphone|ios|regex|objective-c|\n+--------------------+--------------------+----+---+----------+---+---+------+----+------+---+-------+---+---+-----+------+------+----------+------+---+-----+-----------+\n| can anyone expla...|          javascript| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|\n| how can i write ...|                   c| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|\n| i have 2 importa...|     java|networking| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|\n| i have a form th...|javascript|jquery...| 0.0|0.0|       1.0|0.0|0.0|   1.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|\n| i have a text fi...|                  c#| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|\n+--------------------+--------------------+----+---+----------+---+---+------+----+------+---+-------+---+---+-----+------+------+----------+------+---+-----+-----------+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "results_validation_data.show(5)"}, {"cell_type": "code", "execution_count": 32, "id": "3b7ace1c-14c7-4771-b6df-f9b05a23ed24", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "completed iteration20\ncompleted iteration21\ncompleted iteration22\ncompleted iteration23\ncompleted iteration24\ncompleted iteration25\ncompleted iteration26\ncompleted iteration27\ncompleted iteration28\ncompleted iteration29\n"}], "source": "for i in range(20,30):\n    #Join predictions back to the results DataFrame\n    predictions_column = predictions_tags[i]['predictions_column']\n    results_validation_data = results_validation_data.join(predictions_column, \n                                                   results_validation_data[\"post_body_text\"] == predictions_column[f\"post_body_text_{i}\"], \n                                                   how='inner')  \n    results_validation_data = results_validation_data.drop(f\"post_body_text_{i}\")\n    print(f'completed iteration{i}')"}, {"cell_type": "code", "execution_count": 33, "id": "4a46f1d0-0d02-49de-aa34-700405187143", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/01 19:56:15 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:56:15 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:56:15 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:56:15 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:56:15 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:56:16 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:56:16 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:56:16 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:56:16 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:56:16 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:56:16 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:56:16 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:56:16 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:56:16 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:56:17 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:58:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n[Stage 1155:>                                                       (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+----+---+----------+---+---+------+----+------+---+-------+---+---+-----+------+------+----------+------+---+-----+-----------+---------+----+-----------+--------+-----+-------------+-------+----+--------------+---+\n|      post_body_text|           post_tags|java| c#|javascript|php|c++|jquery|html|python|css|android|  c|sql|mysql|arrays|string|sql-server|iphone|ios|regex|objective-c|algorithm|ruby|performance|database|linux|ruby-on-rails|windows|list|multithreading|oop|\n+--------------------+--------------------+----+---+----------+---+---+------+----+------+---+-------+---+---+-----+------+------+----------+------+---+-----+-----------+---------+----+-----------+--------+-----+-------------+-------+----+--------------+---+\n| i am trying to s...|          javascript| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|      0.0| 1.0|        0.0|     0.0|  0.0|          0.0|    0.0| 0.0|           0.0|0.0|\n| i have a form th...|javascript|jquery...| 0.0|0.0|       1.0|0.0|0.0|   1.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|      0.0| 0.0|        0.0|     0.0|  0.0|          0.0|    0.0| 0.0|           0.0|0.0|\n| i have a propert...|c#|sorting|hashtable| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|      0.0| 0.0|        0.0|     0.0|  0.0|          0.0|    0.0| 0.0|           0.0|0.0|\n| i have a variabl...|                 php| 0.0|0.0|       0.0|1.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|      0.0| 0.0|        0.0|     0.0|  0.0|          0.0|    0.0| 0.0|           0.0|0.0|\n| i have this piec...|javascript|decrem...| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|      0.0| 0.0|        0.0|     0.0|  0.0|          0.0|    0.0| 0.0|           0.0|0.0|\n+--------------------+--------------------+----+---+----------+---+---+------+----+------+---+-------+---+---+-----+------+------+----------+------+---+-----+-----------+---------+----+-----------+--------+-----+-------------+-------+----+--------------+---+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "results_validation_data.show(5)"}, {"cell_type": "code", "execution_count": 34, "id": "7850f2c2-27d7-42db-a794-f196733bd26a", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "completed iteration30\ncompleted iteration31\ncompleted iteration32\ncompleted iteration33\ncompleted iteration34\ncompleted iteration35\ncompleted iteration36\ncompleted iteration37\ncompleted iteration38\ncompleted iteration39\n"}], "source": "for i in range(30,40):\n    #Join predictions back to the results DataFrame\n    predictions_column = predictions_tags[i]['predictions_column']\n    results_validation_data = results_validation_data.join(predictions_column, \n                                                   results_validation_data[\"post_body_text\"] == predictions_column[f\"post_body_text_{i}\"], \n                                                   how='inner')  \n    results_validation_data = results_validation_data.drop(f\"post_body_text_{i}\")\n    print(f'completed iteration{i}')"}, {"cell_type": "code", "execution_count": 35, "id": "2f406f8b-d7d0-46cd-aa7f-eb3fba5b98c8", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/01 19:59:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:05 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:05 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:05 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:05 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:05 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 19:59:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:01:10 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n[Stage 1208:>                                                       (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+----+---+----------+---+---+------+----+------+---+-------+---+---+-----+------+------+----------+------+---+-----+-----------+---------+----+-----------+--------+-----+-------------+-------+----+--------------+---+----+-------+----+----+----+--------+-------------+---+--------+----+\n|      post_body_text|           post_tags|java| c#|javascript|php|c++|jquery|html|python|css|android|  c|sql|mysql|arrays|string|sql-server|iphone|ios|regex|objective-c|algorithm|ruby|performance|database|linux|ruby-on-rails|windows|list|multithreading|oop|bash|eclipse|ajax|perl|json|pointers|visual-studio|xml|winforms|linq|\n+--------------------+--------------------+----+---+----------+---+---+------+----+------+---+-------+---+---+-----+------+------+----------+------+---+-----+-----------+---------+----+-----------+--------+-----+-------------+-------+----+--------------+---+----+-------+----+----+----+--------+-------------+---+--------+----+\n| i am trying to s...|          javascript| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|      0.0| 1.0|        0.0|     0.0|  0.0|          0.0|    0.0| 0.0|           0.0|0.0| 0.0|    0.0| 0.0| 0.0| 0.0|     0.0|          0.0|0.0|     0.0| 0.0|\n| i have a form th...|javascript|jquery...| 0.0|0.0|       1.0|0.0|0.0|   1.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|      0.0| 0.0|        0.0|     0.0|  0.0|          0.0|    0.0| 0.0|           0.0|0.0| 0.0|    0.0| 0.0| 0.0| 0.0|     0.0|          0.0|0.0|     0.0| 0.0|\n| i have a propert...|c#|sorting|hashtable| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|      0.0| 0.0|        0.0|     0.0|  0.0|          0.0|    0.0| 0.0|           0.0|0.0| 0.0|    0.0| 0.0| 0.0| 0.0|     0.0|          0.0|0.0|     0.0| 0.0|\n| i have a variabl...|                 php| 0.0|0.0|       0.0|1.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|      0.0| 0.0|        0.0|     0.0|  0.0|          0.0|    0.0| 0.0|           0.0|0.0| 0.0|    0.0| 0.0| 0.0| 0.0|     0.0|          0.0|0.0|     0.0| 0.0|\n| i have this piec...|javascript|decrem...| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|      0.0| 0.0|        0.0|     0.0|  0.0|          0.0|    0.0| 0.0|           0.0|0.0| 0.0|    0.0| 0.0| 0.0| 0.0|     0.0|          0.0|0.0|     0.0| 0.0|\n+--------------------+--------------------+----+---+----------+---+---+------+----+------+---+-------+---+---+-----+------+------+----------+------+---+-----+-----------+---------+----+-----------+--------+-----+-------------+-------+----+--------------+---+----+-------+----+----+----+--------+-------------+---+--------+----+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "results_validation_data.show(5)"}, {"cell_type": "code", "execution_count": 36, "id": "4d10fe89-2a47-412f-b1b4-cf3aa1d150b4", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "completed iteration40\ncompleted iteration41\ncompleted iteration42\ncompleted iteration43\ncompleted iteration44\ncompleted iteration45\ncompleted iteration46\ncompleted iteration47\ncompleted iteration48\ncompleted iteration49\n"}], "source": "for i in range(40,50):\n    #Join predictions back to the results DataFrame\n    predictions_column = predictions_tags[i]['predictions_column']\n    results_validation_data = results_validation_data.join(predictions_column, \n                                                   results_validation_data[\"post_body_text\"] == predictions_column[f\"post_body_text_{i}\"], \n                                                   how='inner')  \n    results_validation_data = results_validation_data.drop(f\"post_body_text_{i}\")\n    print(f'completed iteration{i}')"}, {"cell_type": "code", "execution_count": 37, "id": "2ab497d8-3b13-4ff9-a255-8727d5cd4d17", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/01 20:01:58 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:01:59 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:01:59 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:00 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:00 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:00 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:01 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:02 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:03 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:02:04 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:04:28 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.3 MiB\n[Stage 1271:>                                                       (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+----+---+----------+---+---+------+----+------+---+-------+---+---+-----+------+------+----------+------+---+-----+-----------+---------+----+-----------+--------+-----+-------------+-------+----+--------------+---+----+-------+----+----+----+--------+-------------+---+--------+----+--------+-----+----+---+-----+-----------------+-----------+---------------+----------+-------+\n|      post_body_text|           post_tags|java| c#|javascript|php|c++|jquery|html|python|css|android|  c|sql|mysql|arrays|string|sql-server|iphone|ios|regex|objective-c|algorithm|ruby|performance|database|linux|ruby-on-rails|windows|list|multithreading|oop|bash|eclipse|ajax|perl|json|pointers|visual-studio|xml|winforms|linq|function|class|tsql|wpf|xcode|language-agnostic|asp_dot_net|asp_dot_net-mvc|vb_dot_net|dot_net|\n+--------------------+--------------------+----+---+----------+---+---+------+----+------+---+-------+---+---+-----+------+------+----------+------+---+-----+-----------+---------+----+-----------+--------+-----+-------------+-------+----+--------------+---+----+-------+----+----+----+--------+-------------+---+--------+----+--------+-----+----+---+-----+-----------------+-----------+---------------+----------+-------+\n| am newbie in lar...|         php|laravel| 0.0|0.0|       0.0|1.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|      0.0| 0.0|        0.0|     0.0|  0.0|          0.0|    0.0| 0.0|           0.0|0.0| 0.0|    0.0| 0.0| 0.0| 0.0|     0.0|          0.0|0.0|     0.0| 0.0|     0.0|  0.0| 0.0|0.0|  0.0|              0.0|        0.0|            0.0|       0.0|    0.0|\n| for example i am...|java|static|non-s...| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|      0.0| 0.0|        0.0|     0.0|  0.0|          0.0|    0.0| 0.0|           0.0|0.0| 0.0|    0.0| 0.0| 0.0| 0.0|     0.0|          0.0|0.0|     0.0| 0.0|     0.0|  0.0| 0.0|0.0|  0.0|              0.0|        0.0|            0.0|       0.0|    0.0|\n| how can i close ...|c#|winforms|keybo...| 0.0|1.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   1.0|       0.0|   0.0|0.0|  0.0|        0.0|      0.0| 0.0|        0.0|     0.0|  0.0|          0.0|    0.0| 0.0|           0.0|0.0| 0.0|    0.0| 0.0| 0.0| 0.0|     0.0|          0.0|0.0|     1.0| 0.0|     0.0|  0.0| 0.0|0.0|  0.0|              0.0|        0.0|            0.0|       0.0|    0.0|\n| how can i filter...|linux|bash|sed|aw...| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|      0.0| 0.0|        0.0|     0.0|  0.0|          0.0|    0.0| 0.0|           0.0|0.0| 0.0|    0.0| 0.0| 0.0| 0.0|     0.0|          0.0|0.0|     0.0| 0.0|     0.0|  0.0| 0.0|0.0|  0.0|              0.0|        0.0|            0.0|       0.0|    0.0|\n| i am completely ...|         c#|xml|linq| 0.0|0.0|       0.0|0.0|0.0|   0.0| 0.0|   0.0|0.0|    0.0|0.0|0.0|  0.0|   0.0|   0.0|       0.0|   0.0|0.0|  0.0|        0.0|      0.0| 0.0|        0.0|     0.0|  0.0|          0.0|    0.0| 0.0|           0.0|0.0| 0.0|    0.0| 0.0| 0.0| 0.0|     0.0|          0.0|1.0|     0.0| 1.0|     0.0|  0.0| 0.0|0.0|  0.0|              0.0|        0.0|            0.0|       0.0|    0.0|\n+--------------------+--------------------+----+---+----------+---+---+------+----+------+---+-------+---+---+-----+------+------+----------+------+---+-----+-----------+---------+----+-----------+--------+-----+-------------+-------+----+--------------+---+----+-------+----+----+----+--------+-------------+---+--------+----+--------+-----+----+---+-----+-----------------+-----------+---------------+----------+-------+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "results_validation_data.show(5)"}, {"cell_type": "code", "execution_count": 38, "id": "6555348d-9a93-498f-b1ff-87004a917f1b", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/01 20:04:54 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n                                                                                \r"}], "source": "# Write the DataFrame to GCS in Parquet format\noutput_path1 = \"gs://msca-bdp-student-gcs/Group6/Tag_classification_inference/val_df\"\nval_df.write.mode(\"overwrite\").parquet(output_path1)"}, {"cell_type": "code", "execution_count": 39, "id": "ceb218a7-2c4c-4049-be1c-c314a389f905", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/01 20:05:25 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:25 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:25 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:26 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:26 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:26 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:26 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:26 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:26 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:27 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:27 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:27 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:28 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:05:30 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:07:57 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.5 MiB\n                                                                                \r"}], "source": "# Write the DataFrame to GCS in Parquet format\noutput_path2 = \"gs://msca-bdp-student-gcs/Group6/Tag_classification_inference/results_validation_data\"\nresults_validation_data.write.mode(\"overwrite\").parquet(output_path2)"}, {"cell_type": "code", "execution_count": 40, "id": "9428c6ec-91df-4b3f-bfd0-26854db2fee6", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/01 20:09:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:08 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:09 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:09 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:09 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:09 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:09 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:10 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:10 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:10 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:11 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:09:12 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:11:39 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 91.5 MiB\n[Stage 1407:>                                                       (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+--------------------+--------------------+\n|      post_body_text|           post_tags|      predicted_tags|\n+--------------------+--------------------+--------------------+\n| am newbie in lar...|         php|laravel|               [php]|\n| how can i close ...|c#|winforms|keybo...|[c#, string, winf...|\n| i am completely ...|         c#|xml|linq|         [xml, linq]|\n| i have django in...| python|django|pydev|            [python]|\n| i have problem w...|python|file|dicti...|            [python]|\n+--------------------+--------------------+--------------------+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "#We can also have a look at some of the tags that the model has been able to generate for posts by condensing the data\nfrom pyspark.sql.functions import array, col, when, expr, size\n\nresults_validation_data_with_tags = results_validation_data.withColumn(\"predicted_tags\",array(*[when(col(tag) == 1, \n                                                                                          tag).otherwise(None) \n                                                                                     for tag in top_50_tags]))\n\nresults_validation_data_with_tags = results_validation_data_with_tags.withColumn(\"predicted_tags\",\n                                                                                 expr(\"filter(predicted_tags, x -> x is not null)\"))\n\nresults_validation_data_with_tags.filter(size(col(\"predicted_tags\")) > 0).select('post_body_text','post_tags','predicted_tags').show(5)"}, {"cell_type": "code", "execution_count": 41, "id": "9780576f-d89e-43ec-8984-b2c34eb44a74", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/01 20:12:20 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:20 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:20 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:20 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:23 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:24 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:12:25 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 5.9 MiB\n24/12/01 20:14:48 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 91.8 MiB\n                                                                                \r"}], "source": "# Write the DataFrame to GCS in Parquet format\noutput_path3 = \"gs://msca-bdp-student-gcs/Group6/Tag_classification_inference/results_validation_data_with_tags\"\nresults_validation_data_with_tags.write.mode(\"overwrite\").parquet(output_path3)"}, {"cell_type": "code", "execution_count": 46, "id": "f8c81f5a-e2b7-48e3-9ba2-4f16ce1615bf", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- post_body_text: string (nullable = true)\n |-- post_tags: string (nullable = true)\n |-- java: double (nullable = false)\n |-- c#: double (nullable = false)\n |-- javascript: double (nullable = false)\n |-- php: double (nullable = false)\n |-- c++: double (nullable = false)\n |-- jquery: double (nullable = false)\n |-- html: double (nullable = false)\n |-- python: double (nullable = false)\n |-- css: double (nullable = false)\n |-- android: double (nullable = false)\n |-- c: double (nullable = false)\n |-- sql: double (nullable = false)\n |-- mysql: double (nullable = false)\n |-- arrays: double (nullable = false)\n |-- string: double (nullable = false)\n |-- sql-server: double (nullable = false)\n |-- iphone: double (nullable = false)\n |-- ios: double (nullable = false)\n |-- regex: double (nullable = false)\n |-- objective-c: double (nullable = false)\n |-- algorithm: double (nullable = false)\n |-- ruby: double (nullable = false)\n |-- performance: double (nullable = false)\n |-- database: double (nullable = false)\n |-- linux: double (nullable = false)\n |-- ruby-on-rails: double (nullable = false)\n |-- windows: double (nullable = false)\n |-- list: double (nullable = false)\n |-- multithreading: double (nullable = false)\n |-- oop: double (nullable = false)\n |-- bash: double (nullable = false)\n |-- eclipse: double (nullable = false)\n |-- ajax: double (nullable = false)\n |-- perl: double (nullable = false)\n |-- json: double (nullable = false)\n |-- pointers: double (nullable = false)\n |-- visual-studio: double (nullable = false)\n |-- xml: double (nullable = false)\n |-- winforms: double (nullable = false)\n |-- linq: double (nullable = false)\n |-- function: double (nullable = false)\n |-- class: double (nullable = false)\n |-- tsql: double (nullable = false)\n |-- wpf: double (nullable = false)\n |-- xcode: double (nullable = false)\n |-- language-agnostic: double (nullable = false)\n |-- asp_dot_net: double (nullable = false)\n |-- asp_dot_net-mvc: double (nullable = false)\n |-- vb_dot_net: double (nullable = false)\n |-- dot_net: double (nullable = false)\n |-- predicted_tags: array (nullable = false)\n |    |-- element: string (containsNull = true)\n\n"}], "source": "results_validation_data_with_tags.printSchema()"}, {"cell_type": "code", "execution_count": 47, "id": "5bd34652-594b-46a5-bd9e-10580ce84bf3", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/02 00:59:28 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 00:59:46 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n24/12/02 00:59:46 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n24/12/02 00:59:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n24/12/02 00:59:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n24/12/02 00:59:47 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n"}, {"name": "stdout", "output_type": "stream", "text": "+----+-----+\n|java|count|\n+----+-----+\n|   0|27436|\n|   1| 4665|\n+----+-----+\n\n"}], "source": "val_df.groupBy('java').count().show()"}, {"cell_type": "code", "execution_count": 48, "id": "5e39ee65-1ef9-427e-a5f9-d30505f3c6ca", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/02 01:00:18 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:19 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:19 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:19 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:19 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:19 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:19 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:19 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:20 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:20 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:20 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:20 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:21 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:00:22 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n24/12/02 01:03:06 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 9.9 MiB\n24/12/02 01:03:27 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 9.8 MiB\n24/12/02 01:03:28 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 9.8 MiB\n24/12/02 01:03:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 9.8 MiB\n24/12/02 01:03:29 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 9.8 MiB\n24/12/02 01:03:32 WARN org.apache.spark.scheduler.DAGScheduler: Broadcasting large task binary with size 9.8 MiB\n"}, {"name": "stdout", "output_type": "stream", "text": "+----+-----+\n|java|count|\n+----+-----+\n| 0.0|26899|\n| 1.0| 2880|\n+----+-----+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "results_validation_data.groupBy('java').count().show()"}, {"cell_type": "code", "execution_count": null, "id": "68924b64-1cd9-4fea-a4f8-ef42ae6096a5", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "af2bb57b-fa1a-4023-bdef-dbf30296faaa", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "0c9ab38d-1382-44e2-9936-56d99f02572b", "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "id": "7de673a2-f440-4696-aa1e-9a982e7eec10", "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.15"}}, "nbformat": 4, "nbformat_minor": 5}